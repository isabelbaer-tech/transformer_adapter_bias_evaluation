# nlp_bias_evaluation

Link-Sammlung:

GDrive Folder: 
-https://drive.google.com/drive/folders/1RCD7zCePgE2bbVG7rKuPf-QTQTiX2aCY

- Adapter-Hub:
    - https://colab.research.google.com/github/Adapter-Hub/adapter-transformers/blob/master/notebooks/03_Adapter_Fusion.ipynb#scrollTo=jRqbBgS0BoHJ
    - https://docs.adapterhub.ml/training.html
    - [AdapterHub: A Framework for Adapting Transformers -  paper](https://arxiv.org/abs/2007.07779)
    - [AdapterHub Link](https://adapterhub.ml/)

- Stereoset Dataset:
    - https://github.com/moinnadeem/StereoSet/blob/master/code/evaluation.py
    - [StereoSet: Measuring stereotypical bias in pretrained language models](https://arxiv.org/pdf/2004.09456.pdf)
    - https://www.kaggle.com/crowdflower/political-social-media-posts
    - https://stereoset.mit.edu/

- Other Model Fairness Evaluation:
    - https://www.tensorflow.org/tfx/guide/fairness_indicators
    - https://github.com/tensorflow/model-card-toolkit
    - [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf)
    - https://github.com/Trusted-AI/AIF360
    - [Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic auditing](https://dl.acm.org/doi/abs/10.1145/3351095.3372873)
    - http://stereotropes.bocoup.com/gender






